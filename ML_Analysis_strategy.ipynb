{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from ML_util import *\n",
    "from ML_Analysis_OptimalStimuli import LoadSelectiveData\n",
    "\n",
    "path = \"data/BlueMediumRarePupil_task1-1.csv\"\n",
    "thisData = LoadSelectiveData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ratio = 0.6\n",
    "valid_data_ratio = 0.2\n",
    "test_data_ratio = 0.2\n",
    "\n",
    "trb, vdb, teb = thisData.split_data(train_data_ratio, valid_data_ratio, test_data_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = thisData.ml_train(trb)\n",
    "confusionMatrixDict, jspiritSortedDict = thisData.ml_validate(model, vdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = thisData.ml_test_baseline(model, teb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrixOptimal = results[\"cm_multiply\"]\n",
    "for i in range(13):\n",
    "    print(\"====================\")\n",
    "    print(f\"participant {i}\")\n",
    "    thisConfusionMatrix = confusionMatrixOptimal\n",
    "    print(f\"Accuracy for verification: {accuracyMeasurementForVerification(thisConfusionMatrix, i)}\")\n",
    "    print(f\"FAR: {BiometricEvaluation(thisConfusionMatrix, i, 'FAR')}\")\n",
    "    print(f\"FRR: {BiometricEvaluation(thisConfusionMatrix, i, 'FRR')}\")\n",
    "    tp = thisConfusionMatrix[i, i]\n",
    "    fn = thisConfusionMatrix[i,:].sum() - tp\n",
    "    fp = thisConfusionMatrix[:,i].sum() - tp\n",
    "    print(f\"tp: {tp}, fn: {fn}, fp: {fp}\")\n",
    "    \n",
    "\n",
    "visualize_cm(confusionMatrixOptimal, 'RF', \"Baseline\")\n",
    "# accuracyMeasurement(confusionMatrixOptimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_cm = confusionMatrixDict['shape']\n",
    "size_cm = confusionMatrixDict['size']\n",
    "orientation_cm = confusionMatrixDict['orientation']\n",
    "hue_cm = confusionMatrixDict['hue']\n",
    "brightness_cm = confusionMatrixDict['brightness']\n",
    "\n",
    "total_cm = reduce(lambda acc, cur: np.add(acc, cur), [shape_cm, size_cm, orientation_cm, hue_cm, brightness_cm], np.zeros((13,13)))\n",
    "\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_shape_cm.npy'), shape_cm)\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_size_cm.npy'), size_cm)\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_brightness_cm.npy'), brightness_cm)\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_hue_cm.npy'), hue_cm)\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_orientation_cm.npy'), orientation_cm)\n",
    "# np.save(os.path.join(os.getcwd(), 'ml-results', 'medium', 'new_task_cm', 'pupil_task1_val_total_cm.npy'), total_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cm(total_cm, 'RF', 'Val Total')\n",
    "accuracyMeasurement(total_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jspiritSortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function asarray> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m strategy1 \u001b[38;5;241m=\u001b[39m thisData\u001b[38;5;241m.\u001b[39mstimuli_strategy1(jspiritSortedDict, teb)\n\u001b[1;32m----> 2\u001b[0m results1 \u001b[38;5;241m=\u001b[39m \u001b[43mthisData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mml_test_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\IdentiGaze\\ML_Analysis_OptimalStimuli.py:141\u001b[0m, in \u001b[0;36mLoadSelectiveData.ml_test_strategy\u001b[1;34m(self, model, strategy_dict, test_data_block)\u001b[0m\n\u001b[0;32m    139\u001b[0m     this_data \u001b[38;5;241m=\u001b[39m strategy_dict[participant]\n\u001b[0;32m    140\u001b[0m     stack_index, stack_y \u001b[38;5;241m=\u001b[39m stack_ydata_from_anything(total_y, this_data[\u001b[38;5;241m0\u001b[39m], this_data[\u001b[38;5;241m1\u001b[39m], this_data[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 141\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mlatefusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     totalResults[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticipant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m totalResults\n",
      "File \u001b[1;32m~\\IdentiGaze\\ML_util.py:218\u001b[0m, in \u001b[0;36mlatefusion\u001b[1;34m(clf, x_data, stack_index, stack_y)\u001b[0m\n\u001b[0;32m    216\u001b[0m f1_plus \u001b[38;5;241m=\u001b[39m f1_score(stack_y, plus_predict, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    217\u001b[0m f1_multiply \u001b[38;5;241m=\u001b[39m f1_score(stack_y, multiply_predict, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 218\u001b[0m f1_max \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstack_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm_plus\u001b[39m\u001b[38;5;124m'\u001b[39m:cm_plus, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm_multiply\u001b[39m\u001b[38;5;124m'\u001b[39m:cm_multiply, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm_max\u001b[39m\u001b[38;5;124m'\u001b[39m:cm_max,\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_plus\u001b[39m\u001b[38;5;124m'\u001b[39m:acc_plus, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_multiply\u001b[39m\u001b[38;5;124m'\u001b[39m:acc_multiply, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_max\u001b[39m\u001b[38;5;124m'\u001b[39m:acc_max,\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_plus\u001b[39m\u001b[38;5;124m'\u001b[39m:precision_plus, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_multiply\u001b[39m\u001b[38;5;124m'\u001b[39m:precision_multiply, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_max\u001b[39m\u001b[38;5;124m'\u001b[39m:precision_max,\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_plus\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_plus, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_multiply\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_multiply, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_max\u001b[39m\u001b[38;5;124m'\u001b[39m:f1_max\n\u001b[0;32m    225\u001b[0m }\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:110\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m--> 110\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\utils\\validation.py:1179\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03m    If `y` is not a 1D array or a 2D array with a single row or column.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[1;32m-> 1179\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\envs\\mlanalysis\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function asarray> returned NULL without setting an error"
     ]
    }
   ],
   "source": [
    "strategy1 = thisData.stimuli_strategy1(jspiritSortedDict, teb)\n",
    "results1 = thisData.ml_test_strategy(model, strategy1, teb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, participant in enumerate(results1):\n",
    "    print(\"====================\")\n",
    "    print(participant)\n",
    "    thisConfusionMatrix = results1[participant][\"cm_multiply\"]\n",
    "    print(f\"Accuracy for verification: {accuracyMeasurementForVerification(thisConfusionMatrix, i)}\")\n",
    "    print(f\"FAR: {BiometricEvaluation(thisConfusionMatrix, i, 'FAR')}\")\n",
    "    print(f\"FRR: {BiometricEvaluation(thisConfusionMatrix, i, 'FRR')}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy2 = thisData.stimuli_strategy2(confusionMatrixDict, teb)\n",
    "results2 = thisData.ml_test_strategy(model, strategy2, teb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetParticipant = \"participant_0\"\n",
    "targetConfusionMatrix = results2[targetParticipant][\"cm_multiply\"]\n",
    "visualize_cm(normalize_cm(targetConfusionMatrix), 'rf', targetParticipant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, participant in enumerate(results2):\n",
    "    # print(\"====================\")\n",
    "    # print(participant)\n",
    "    thisConfusionMatrix = results2[participant][\"cm_multiply\"]\n",
    "    # print(f\"{accuracyMeasurementForVerification(thisConfusionMatrix, i)}    {BiometricEvaluation(thisConfusionMatrix, i, 'FAR')}    {BiometricEvaluation(thisConfusionMatrix, i, 'FRR')}\")\n",
    "\n",
    "    print(f\"Accuracy for verification: {accuracyMeasurementForVerification(thisConfusionMatrix, i)}\")\n",
    "    print(f\"FAR: {BiometricEvaluation(thisConfusionMatrix, i, 'FAR')}\")\n",
    "    print(f\"FRR: {BiometricEvaluation(thisConfusionMatrix, i, 'FRR')}\")\n",
    "\n",
    "    tp = thisConfusionMatrix[i, i]\n",
    "    fn = thisConfusionMatrix[i,:].sum() - tp\n",
    "    fp = thisConfusionMatrix[:,i].sum() - tp\n",
    "    print(f\"tp: {tp}, fn: {fn}, fp: {fp}\")\n",
    "\n",
    "    visualize_cm(thisConfusionMatrix, 'rf', participant)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy1 = thisData.stimuli_strategy1(jspiritSortedDict, teb)\n",
    "thisData.ml_test_strategy_verification(model, strategy1, teb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
